#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨±èŠ±åŠ¨æ¼«åˆ†é›†URLçˆ¬è™« - å¯è§†åŒ–ç‰ˆæœ¬
ä¸“é—¨çˆ¬å–åŠ¨æ¼«è¯¦æƒ…é¡µçš„åˆ†é›†åˆ—è¡¨ï¼Œç”Ÿæˆå®Œæ•´URL
"""

import tkinter as tk
from tkinter import ttk, messagebox, scrolledtext, filedialog
import requests
from bs4 import BeautifulSoup
import re
import json
import os
import threading
import time
from datetime import datetime
from urllib.parse import urljoin, urlparse

class EpisodeCrawlerGUI:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("ğŸŒ¸ æ¨±èŠ±åŠ¨æ¼«åˆ†é›†URLçˆ¬è™«")
        self.root.geometry("1000x700")
        self.root.configure(bg='#f8f9fa')
        
        self.base_url = "http://www.iyinghua.com"
        self.episodes_data = []
        self.setup_ui()
        
    def setup_ui(self):
        """è®¾ç½®UIç•Œé¢"""
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root, padding="20")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # é…ç½®ç½‘æ ¼æƒé‡
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)
        
        # æ ‡é¢˜
        title_label = tk.Label(
            main_frame, 
            text="ğŸŒ¸ æ¨±èŠ±åŠ¨æ¼«åˆ†é›†URLçˆ¬è™«", 
            font=("Microsoft YaHei", 20, "bold"),
            fg="#2c3e50",
            bg="#f8f9fa"
        )
        title_label.grid(row=0, column=0, columnspan=3, pady=(0, 20))
        
        # è¾“å…¥åŒºåŸŸ
        input_frame = ttk.LabelFrame(main_frame, text="ğŸ”— åŠ¨æ¼«é¡µé¢URLè¾“å…¥", padding="10")
        input_frame.grid(row=1, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 15))
        input_frame.columnconfigure(0, weight=1)
        
        # URLè¾“å…¥æ¡†
        self.url_entry = ttk.Entry(input_frame, font=("Consolas", 11), width=60)
        self.url_entry.grid(row=0, column=0, sticky=(tk.W, tk.E), padx=(0, 10))
        self.url_entry.insert(0, "http://www.iyinghua.com/show/6556.html")
        
        # æŒ‰é’®åŒºåŸŸ
        button_frame = ttk.Frame(input_frame)
        button_frame.grid(row=0, column=1)
        
        self.crawl_btn = ttk.Button(
            button_frame,
            text="ğŸ•·ï¸ å¼€å§‹çˆ¬å–",
            command=self.start_crawling,
            style='Primary.TButton'
        )
        self.crawl_btn.pack(side=tk.LEFT, padx=(0, 5))
        
        self.clear_btn = ttk.Button(
            button_frame,
            text="ğŸ—‘ï¸ æ¸…ç©º",
            command=self.clear_all
        )
        self.clear_btn.pack(side=tk.LEFT, padx=(0, 5))
        
        self.export_btn = ttk.Button(
            button_frame,
            text="ğŸ“¥ å¯¼å‡º",
            command=self.export_data,
            state="disabled"
        )
        self.export_btn.pack(side=tk.LEFT)
        
        # ä¿¡æ¯æ˜¾ç¤ºåŒºåŸŸ
        info_frame = ttk.LabelFrame(main_frame, text="ğŸ“Š åŠ¨æ¼«ä¿¡æ¯", padding="10")
        info_frame.grid(row=2, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 15))
        
        # ä¿¡æ¯æ ‡ç­¾
        self.title_label = ttk.Label(info_frame, text="åŠ¨æ¼«æ ‡é¢˜: -", font=("Microsoft YaHei", 12, "bold"))
        self.title_label.grid(row=0, column=0, sticky=tk.W, pady=2)
        
        self.episodes_label = ttk.Label(info_frame, text="æ€»é›†æ•°: -", font=("Microsoft YaHei", 11))
        self.episodes_label.grid(row=1, column=0, sticky=tk.W, pady=2)
        
        self.url_label = ttk.Label(info_frame, text="é¡µé¢URL: -", font=("Microsoft YaHei", 10))
        self.url_label.grid(row=2, column=0, sticky=tk.W, pady=2)
        
        # ç»“æœè¡¨æ ¼
        table_frame = ttk.LabelFrame(main_frame, text="ğŸ“‹ åˆ†é›†åˆ—è¡¨", padding="10")
        table_frame.grid(row=3, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 15))
        table_frame.columnconfigure(0, weight=1)
        table_frame.rowconfigure(0, weight=1)
        
        # åˆ›å»ºTreeview
        columns = ("é›†æ•°", "æ ‡é¢˜", "å®Œæ•´URL")
        self.tree = ttk.Treeview(table_frame, columns=columns, show="headings", height=8)
        
        # è®¾ç½®åˆ—å®½å’Œå¯¹é½æ–¹å¼
        self.tree.heading("é›†æ•°", text="é›†æ•°")
        self.tree.heading("æ ‡é¢˜", text="æ ‡é¢˜")
        self.tree.heading("å®Œæ•´URL", text="å®Œæ•´URL")
        
        self.tree.column("é›†æ•°", width=80, anchor=tk.CENTER)
        self.tree.column("æ ‡é¢˜", width=120, anchor=tk.W)
        self.tree.column("å®Œæ•´URL", width=600, anchor=tk.W)
        
        # æ·»åŠ æ»šåŠ¨æ¡
        scrollbar = ttk.Scrollbar(table_frame, orient=tk.VERTICAL, command=self.tree.yview)
        self.tree.configure(yscrollcommand=scrollbar.set)
        
        self.tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        # æ—¥å¿—åŒºåŸŸ
        log_frame = ttk.LabelFrame(main_frame, text="ğŸ“ çˆ¬å–æ—¥å¿—", padding="10")
        log_frame.grid(row=4, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S))
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
        
        self.log_text = scrolledtext.ScrolledText(
            log_frame,
            font=("Consolas", 9),
            height=6,
            wrap=tk.WORD,
            bg="#2b2b2b",
            fg="#ffffff"
        )
        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # è¿›åº¦æ¡
        self.progress = ttk.Progressbar(
            main_frame,
            mode='indeterminate',
            length=300
        )
        self.progress.grid(row=5, column=0, columnspan=3, pady=(10, 0))
        
        # é…ç½®æƒé‡
        main_frame.rowconfigure(3, weight=2)
        main_frame.rowconfigure(4, weight=1)
        
        # è®¾ç½®æ ·å¼
        style = ttk.Style()
        style.configure('Primary.TButton', background='#007bff', foreground='white')
        
    def log_message(self, message, level="INFO"):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        color_map = {
            "INFO": "#00ff00",
            "WARNING": "#ffff00", 
            "ERROR": "#ff0000",
            "SUCCESS": "#00ff00"
        }
        
        self.log_text.insert(tk.END, f"[{timestamp}] [{level}] {message}\n")
        self.log_text.tag_add(level, f"{self.log_text.index(tk.END)}-2l", f"{self.log_text.index(tk.END)}-1l")
        self.log_text.tag_config(level, foreground=color_map.get(level, "#ffffff"))
        self.log_text.see(tk.END)
        self.root.update_idletasks()
        
    def validate_url(self, url):
        """éªŒè¯URLæ ¼å¼"""
        try:
            parsed = urlparse(url)
            if not parsed.scheme or not parsed.netloc:
                return False
            if 'iyinghua.com' not in parsed.netloc:
                return False
            if not parsed.path.startswith('/show/'):
                return False
            return True
        except:
            return False
            
    def extract_anime_info(self, soup):
        """æå–åŠ¨æ¼«åŸºæœ¬ä¿¡æ¯"""
        try:
            # æå–æ ‡é¢˜
            title = "æœªçŸ¥åŠ¨æ¼«"
            title_elem = soup.find('h1')
            if title_elem:
                title = title_elem.get_text().strip()
            else:
                title_elem = soup.find('title')
                if title_elem:
                    title = title_elem.get_text().strip()
                    # æ¸…ç†æ ‡é¢˜
                    title = re.sub(r'[|_-].*', '', title).strip()
            
            return title
        except Exception as e:
            self.log_message(f"æå–åŠ¨æ¼«ä¿¡æ¯å¤±è´¥: {str(e)}", "ERROR")
            return "æœªçŸ¥åŠ¨æ¼«"
            
    def extract_episodes(self, soup):
        """æå–åˆ†é›†ä¿¡æ¯"""
        episodes = []
        try:
            # æŸ¥æ‰¾åˆ†é›†åˆ—è¡¨
            movurl_div = soup.find('div', class_='movurl')
            if not movurl_div:
                # å°è¯•å…¶ä»–å¯èƒ½çš„é€‰æ‹©å™¨
                movurl_div = soup.find('div', id='main0')
                if not movurl_div:
                    movurl_div = soup
            
            # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥
            links = movurl_div.find_all('a', href=True)
            
            for link in links:
                href = link.get('href', '').strip()
                title = link.get_text().strip()
                
                # éªŒè¯é“¾æ¥æ ¼å¼
                if href and re.match(r'/v/\d+-\d+\.html', href):
                    full_url = urljoin(self.base_url, href)
                    
                    # æå–é›†æ•°
                    episode_match = re.search(r'-(\d+)\.html', href)
                    episode_num = int(episode_match.group(1)) if episode_match else 0
                    
                    episodes.append({
                        'episode': episode_num,
                        'title': title,
                        'url': full_url,
                        'relative_url': href
                    })
            
            # æŒ‰é›†æ•°æ’åº
            episodes.sort(key=lambda x: x['episode'])
            return episodes
            
        except Exception as e:
            self.log_message(f"æå–åˆ†é›†ä¿¡æ¯å¤±è´¥: {str(e)}", "ERROR")
            return []
            
    def crawl_episodes(self, url):
        """çˆ¬å–åˆ†é›†ä¿¡æ¯"""
        self.log_message(f"ğŸš€ å¼€å§‹çˆ¬å–: {url}")
        
        try:
            # éªŒè¯URL
            if not self.validate_url(url):
                self.log_message("âŒ æ— æ•ˆçš„åŠ¨æ¼«é¡µé¢URL", "ERROR")
                return False
                
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            }
            
            self.log_message("ğŸŒ å‘é€è¯·æ±‚...")
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            response.encoding = 'utf-8'
            
            self.log_message(f"âœ… è·å–é¡µé¢æˆåŠŸ ({len(response.text)} å­—ç¬¦)")
            
            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æå–ä¿¡æ¯
            anime_title = self.extract_anime_info(soup)
            episodes = self.extract_episodes(soup)
            
            if not episodes:
                self.log_message("âš ï¸ æœªæ‰¾åˆ°åˆ†é›†ä¿¡æ¯ï¼Œå°è¯•å…¶ä»–é€‰æ‹©å™¨...", "WARNING")
                # å°è¯•æ›´å¹¿æ³›çš„æœç´¢
                all_links = soup.find_all('a', href=re.compile(r'/v/\d+-\d+\.html'))
                for link in all_links:
                    href = link.get('href', '').strip()
                    title = link.get_text().strip()
                    if href:
                        full_url = urljoin(self.base_url, href)
                        episode_match = re.search(r'-(\d+)\.html', href)
                        episode_num = int(episode_match.group(1)) if episode_match else 0
                        episodes.append({
                            'episode': episode_num,
                            'title': title,
                            'url': full_url,
                            'relative_url': href
                        })
                
                episodes.sort(key=lambda x: x['episode'])
            
            # æ›´æ–°UI
            self.title_label.config(text=f"åŠ¨æ¼«æ ‡é¢˜: {anime_title}")
            self.episodes_label.config(text=f"æ€»é›†æ•°: {len(episodes)}")
            self.url_label.config(text=f"é¡µé¢URL: {url}")
            
            # æ›´æ–°è¡¨æ ¼
            self.update_episodes_table(episodes)
            
            self.episodes_data = episodes
            self.export_btn.config(state="normal")
            
            self.log_message(f"âœ… çˆ¬å–å®Œæˆï¼å…±æ‰¾åˆ° {len(episodes)} é›†", "SUCCESS")
            return True
            
        except requests.RequestException as e:
            self.log_message(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}", "ERROR")
            return False
        except Exception as e:
            self.log_message(f"âŒ çˆ¬å–å¤±è´¥: {str(e)}", "ERROR")
            return False
            
    def update_episodes_table(self, episodes):
        """æ›´æ–°åˆ†é›†è¡¨æ ¼"""
        # æ¸…ç©ºè¡¨æ ¼
        for item in self.tree.get_children():
            self.tree.delete(item)
            
        # æ·»åŠ æ•°æ®
        for ep in episodes:
            self.tree.insert('', 'end', values=(
                ep['episode'],
                ep['title'],
                ep['url']
            ))
            
    def start_crawling(self):
        """å¼€å§‹çˆ¬å–"""
        url = self.url_entry.get().strip()
        if not url:
            messagebox.showwarning("è­¦å‘Š", "è¯·è¾“å…¥åŠ¨æ¼«é¡µé¢URL")
            return
            
        # ç¦ç”¨æŒ‰é’®ï¼Œæ˜¾ç¤ºè¿›åº¦
        self.crawl_btn.config(state="disabled")
        self.export_btn.config(state="disabled")
        self.progress.start()
        
        # æ¸…ç©ºä¹‹å‰çš„æ•°æ®
        self.clear_all()
        
        # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œçˆ¬å–
        thread = threading.Thread(target=self.crawl_in_background, args=(url,))
        thread.daemon = True
        thread.start()
        
    def crawl_in_background(self, url):
        """åå°çˆ¬å–"""
        try:
            success = self.crawl_episodes(url)
            
            if success and self.episodes_data:
                messagebox.showinfo("æˆåŠŸ", f"çˆ¬å–å®Œæˆï¼å…±æ‰¾åˆ° {len(self.episodes_data)} é›†")
            elif success:
                messagebox.showwarning("æç¤º", "çˆ¬å–å®Œæˆï¼Œä½†æœªæ‰¾åˆ°åˆ†é›†ä¿¡æ¯")
            else:
                messagebox.showerror("é”™è¯¯", "çˆ¬å–å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—")
                
        except Exception as e:
            self.log_message(f"åå°ä»»åŠ¡é”™è¯¯: {str(e)}", "ERROR")
            messagebox.showerror("é”™è¯¯", f"çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            
        finally:
            # æ¢å¤æŒ‰é’®çŠ¶æ€
            self.crawl_btn.config(state="normal")
            self.progress.stop()
            
    def export_data(self):
        """å¯¼å‡ºæ•°æ®"""
        if not self.episodes_data:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")
            return
            
        # è·å–åŠ¨æ¼«æ ‡é¢˜
        anime_title = self.title_label.cget('text').replace("åŠ¨æ¼«æ ‡é¢˜: ", "")
        if anime_title == "-":
            anime_title = "æœªçŸ¥åŠ¨æ¼«"
            
        # é€‰æ‹©å¯¼å‡ºæ ¼å¼
        file_types = [
            ("JSONæ–‡ä»¶", "*.json"),
            ("æ–‡æœ¬æ–‡ä»¶", "*.txt"),
            ("CSVæ–‡ä»¶", "*.csv")
        ]
        
        filename = filedialog.asksaveasfilename(
            title="å¯¼å‡ºåˆ†é›†æ•°æ®",
            initialfile=f"{anime_title}_episodes",
            filetypes=file_types,
            defaultextension=".json"
        )
        
        if not filename:
            return
            
        try:
            if filename.endswith('.json'):
                self.export_json(filename, anime_title)
            elif filename.endswith('.txt'):
                self.export_txt(filename, anime_title)
            elif filename.endswith('.csv'):
                self.export_csv(filename, anime_title)
                
            messagebox.showinfo("æˆåŠŸ", f"æ•°æ®å·²å¯¼å‡ºåˆ°: {filename}")
            self.log_message(f"ğŸ“¥ æ•°æ®å¯¼å‡ºæˆåŠŸ: {filename}", "SUCCESS")
            
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            self.log_message(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}", "ERROR")
            
    def export_json(self, filename, anime_title):
        """å¯¼å‡ºJSONæ ¼å¼"""
        export_data = {
            "anime_name": anime_title,
            "total_episodes": len(self.episodes_data),
            "base_url": self.base_url,
            "crawl_time": datetime.now().isoformat(),
            "episodes": self.episodes_data
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
            
    def export_txt(self, filename, anime_title):
        """å¯¼å‡ºæ–‡æœ¬æ ¼å¼"""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"ğŸŒ¸ æ¨±èŠ±åŠ¨æ¼«åˆ†é›†URLåˆ—è¡¨\n")
            f.write(f"{'='*50}\n\n")
            f.write(f"åŠ¨æ¼«åç§°: {anime_title}\n")
            f.write(f"æ€»é›†æ•°: {len(self.episodes_data)}\n")
            f.write(f"çˆ¬å–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ¥æºç½‘ç«™: {self.base_url}\n\n")
            f.write(f"{'='*50}\n\n")
            
            for ep in self.episodes_data:
                f.write(f"ç¬¬{ep['episode']:02d}é›†: {ep['url']}\n")
                
    def export_csv(self, filename, anime_title):
        """å¯¼å‡ºCSVæ ¼å¼"""
        import csv
        
        with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(['é›†æ•°', 'æ ‡é¢˜', 'å®Œæ•´URL', 'ç›¸å¯¹URL'])
            
            for ep in self.episodes_data:
                writer.writerow([ep['episode'], ep['title'], ep['url'], ep['relative_url']])
                
    def clear_all(self):
        """æ¸…ç©ºæ‰€æœ‰å†…å®¹"""
        self.title_label.config(text="åŠ¨æ¼«æ ‡é¢˜: -")
        self.episodes_label.config(text="æ€»é›†æ•°: -")
        self.url_label.config(text="é¡µé¢URL: -")
        
        # æ¸…ç©ºè¡¨æ ¼
        for item in self.tree.get_children():
            self.tree.delete(item)
            
        self.log_text.delete(1.0, tk.END)
        self.episodes_data = []
        self.export_btn.config(state="disabled")
        
    def run(self):
        """è¿è¡Œåº”ç”¨"""
        self.log_message("ğŸŒ¸ æ¨±èŠ±åŠ¨æ¼«åˆ†é›†URLçˆ¬è™«å·²å¯åŠ¨")
        self.log_message("ğŸ’¡ è¯·è¾“å…¥åŠ¨æ¼«è¯¦æƒ…é¡µURLï¼Œå¦‚: http://www.iyinghua.com/show/6556.html")
        self.log_message("ğŸ“– ç¨‹åºå°†è‡ªåŠ¨æå–æ‰€æœ‰åˆ†é›†çš„å®Œæ•´æ’­æ”¾URL")
        self.root.mainloop()

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    required_packages = ['requests', 'beautifulsoup4']
    missing_packages = []
    
    for package in required_packages:
        try:
            if package == 'beautifulsoup4':
                import bs4
            else:
                __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("âŒ è¯·å®‰è£…ä»¥ä¸‹ä¾èµ–åŒ…:")
        print(f"pip install {' '.join(missing_packages)}")
        import sys
        sys.exit(1)
        
    app = EpisodeCrawlerGUI()
    app.run()