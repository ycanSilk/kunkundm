#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ— å¹¿å‘Šæ¨±èŠ±åŠ¨æ¼«è§†é¢‘é“¾æ¥æå–å™¨
è‡ªåŠ¨å»é™¤åµŒå¥—å¹¿å‘Šï¼Œè·å–çº¯å‡€è§†é¢‘é“¾æ¥
"""

import requests
import re
import json
import time
from urllib.parse import urljoin, urlparse, parse_qs
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from bs4 import BeautifulSoup
import subprocess
import os

class AdFreeVideoExtractor:
    """æ— å¹¿å‘Šè§†é¢‘é“¾æ¥æå–å™¨"""
    
    def __init__(self, headless=True):
        self.headless = headless
        self.driver = None
        self.session = requests.Session()
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Referer': 'http://www.iyinghua.com/',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        })
        
        # å¹¿å‘Šå…ƒç´ é€‰æ‹©å™¨
        self.ad_selectors = [
            '#adv_wrap_hh',
            '.advertisement',
            '.ad-banner',
            '#ad-container',
            '.video-ad',
            '[id*="adv"]',
            '[class*="ad"]',
            'iframe[src*="ad"]',
            'iframe[src*="advertisement"]'
        ]
    
    def init_driver(self):
        """åˆå§‹åŒ–æµè§ˆå™¨é©±åŠ¨"""
        try:
            from webdriver_manager.chrome import ChromeDriverManager
            from selenium.webdriver.chrome.service import Service
            
            chrome_options = Options()
            if self.headless:
                chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            # æ·»åŠ å¹¿å‘Šæ‹¦æˆªæ‰©å±•
            chrome_options.add_argument('--disable-extensions-except')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--disable-plugins')
            
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            return True
        except Exception as e:
            print(f"åˆå§‹åŒ–é©±åŠ¨å¤±è´¥: {e}")
            return False
    
    def remove_ads_from_page(self):
        """ä»é¡µé¢ä¸­ç§»é™¤å¹¿å‘Šå…ƒç´ """
        try:
            # ç§»é™¤å·²çŸ¥çš„å¹¿å‘Šå®¹å™¨
            for selector in self.ad_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        self.driver.execute_script("arguments[0].remove();", element)
                        print(f"å·²ç§»é™¤å¹¿å‘Šå…ƒç´ : {selector}")
                except:
                    continue
            
            # ç§»é™¤ç‰¹å®šçš„å¹¿å‘ŠHTML
            ad_html_patterns = [
                'adv_wrap_hh',
                'id="adv_wrap_hh"',
                'evewan.com/visitor.html',
                'sogowan.com',
                'img-random-hm'
            ]
            
            for pattern in ad_html_patterns:
                try:
                    script = f"""
                    var elements = document.querySelectorAll('*');
                    for (var i = 0; i < elements.length; i++) {
                        if (elements[i].outerHTML && elements[i].outerHTML.includes('{pattern}')) {
                            elements[i].remove();
                        }
                    }
                    """
                    self.driver.execute_script(script)
                except:
                    continue
            
            # ç§»é™¤æ‰€æœ‰iframeå¹¿å‘Š
            try:
                iframes = self.driver.find_elements(By.TAG_NAME, 'iframe')
                for iframe in iframes:
                    src = iframe.get_attribute('src')
                    if src and ('ad' in src.lower() or 'visitor' in src.lower()):
                        self.driver.execute_script("arguments[0].remove();", iframe)
            except:
                pass
                
        except Exception as e:
            print(f"ç§»é™¤å¹¿å‘Šå¤±è´¥: {e}")
    
    def extract_clean_video_url(self, page_url):
        """
        æå–æ— å¹¿å‘Šçš„è§†é¢‘URL
        
        Args:
            page_url: æ¨±èŠ±åŠ¨æ¼«é¡µé¢URL
            
        Returns:
            dict: åŒ…å«æ— å¹¿å‘Šè§†é¢‘é“¾æ¥çš„ä¿¡æ¯
        """
        if not self.init_driver():
            return None
        
        try:
            print(f"æ­£åœ¨è®¿é—®é¡µé¢: {page_url}")
            self.driver.get(page_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            WebDriverWait(self.driver, 15).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # ç­‰å¾…è§†é¢‘å…ƒç´ åŠ è½½
            time.sleep(3)
            
            # ç§»é™¤å¹¿å‘Š
            self.remove_ads_from_page()
            
            # è·å–æ¸…ç†åçš„é¡µé¢æºä»£ç 
            clean_page_source = self.driver.page_source
            
            # æå–æ— å¹¿å‘Šçš„è§†é¢‘é“¾æ¥
            clean_sources = self._extract_clean_sources(clean_page_source)
            
            # éªŒè¯å’Œä¼˜åŒ–é“¾æ¥
            optimized_sources = self._optimize_video_urls(clean_sources)
            
            return {
                'success': True,
                'page_url': page_url,
                'clean_sources': optimized_sources,
                'ad_removed': True,
                'original_sources': self._extract_original_sources(page_url)
            }
            
        except Exception as e:
            print(f"æå–æ— å¹¿å‘Šè§†é¢‘å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'clean_sources': []
            }
        finally:
            if self.driver:
                self.driver.quit()
    
    def _extract_clean_sources(self, page_source):
        """ä»æ¸…ç†åçš„é¡µé¢æå–è§†é¢‘æº"""
        sources = []
        
        try:
            # æŸ¥æ‰¾çœŸå®çš„m3u8é“¾æ¥ï¼ˆå»é™¤å¹¿å‘Šå‚æ•°ï¼‰
            
            # æ–¹æ³•1: ä»tup.iyinghua.comæå–çº¯å‡€URL
            tup_pattern = r'https://tup\.iyinghua\.com/\?vid=([^&"\']+)'
            tup_matches = re.findall(tup_pattern, page_source)
            
            for vid_param in tup_matches:
                # è§£ç URLå‚æ•°
                clean_url = vid_param.replace('$mp4', '').split('$')[0]
                if clean_url.startswith('https://') and '.m3u8' in clean_url:
                    sources.append({
                        'type': 'm3u8',
                        'url': clean_url,
                        'quality': self._extract_quality_from_url(clean_url),
                        'source': 'tup.iyinghua.com',
                        'ad_free': True
                    })
            
            # æ–¹æ³•2: ç›´æ¥æå–m3u8é“¾æ¥
            m3u8_pattern = r'https://[^"\']+\.m3u8[^"\']*'
            m3u8_urls = re.findall(m3u8_pattern, page_source)
            
            for url in m3u8_urls:
                # è¿‡æ»¤æ‰åŒ…å«å¹¿å‘Šå‚æ•°çš„URL
                if not any(ad_domain in url for ad_domain in ['evewan.com', 'sogowan.com']):
                    clean_url = self._clean_url_parameters(url)
                    sources.append({
                        'type': 'm3u8',
                        'url': clean_url,
                        'quality': self._extract_quality_from_url(clean_url),
                        'source': 'direct',
                        'ad_free': True
                    })
            
            # æ–¹æ³•3: ä»JavaScripté…ç½®æå–
            js_configs = [
                r'player_aaaa\s*=\s*({[^}]+"url"[^}]+})',
                r'dpVideo\s*=\s*({[^}]+"url"[^}]+})',
                r'config\s*=\s*({[^}]+"video"[^}]+})'
            ]
            
            for pattern in js_configs:
                matches = re.findall(pattern, page_source)
                for match in matches:
                    try:
                        config = json.loads(match)
                        video_url = None
                        
                        if 'url' in config:
                            video_url = config['url']
                        elif 'video' in config and 'url' in config['video']:
                            video_url = config['video']['url']
                        
                        if video_url and '.m3u8' in video_url and not any(ad_domain in video_url for ad_domain in ['evewan.com', 'sogowan.com']):
                            clean_url = self._clean_url_parameters(video_url)
                            sources.append({
                                'type': 'm3u8',
                                'url': clean_url,
                                'quality': config.get('quality', 'auto'),
                                'source': 'javascript_config',
                                'ad_free': True
                            })
                    except:
                        continue
        
        except Exception as e:
            print(f"æå–æ¸…ç†è§†é¢‘æºå¤±è´¥: {e}")
        
        return sources
    
    def _clean_url_parameters(self, url):
        """æ¸…ç†URLä¸­çš„å¹¿å‘Šå‚æ•°"""
        try:
            # ç§»é™¤å¹¿å‘Šç›¸å…³å‚æ•°
            clean_url = re.sub(r'\$[^&]*$', '', url)
            clean_url = re.sub(r'&ad[^&]*', '', clean_url)
            clean_url = re.sub(r'\?ad[^&]*', '', clean_url)
            
            return clean_url
        except:
            return url
    
    def _extract_quality_from_url(self, url):
        """ä»URLæå–è§†é¢‘è´¨é‡"""
        url_lower = url.lower()
        
        if '1080' in url_lower:
            return '1080p'
        elif '720' in url_lower:
            return '720p'
        elif '480' in url_lower:
            return '480p'
        elif '360' in url_lower:
            return '360p'
        else:
            return 'auto'
    
    def _extract_original_sources(self, page_url):
        """æå–åŸå§‹è§†é¢‘æºç”¨äºå¯¹æ¯”"""
        try:
            response = self.session.get(page_url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æå–é¡µé¢åŸºæœ¬ä¿¡æ¯
            title = soup.find('title')
            video_title = title.get_text(strip=True) if title else "æœªçŸ¥"
            
            return {
                'title': video_title,
                'url': page_url
            }
        except:
            return {'title': 'æœªçŸ¥', 'url': page_url}
    
    def validate_clean_url(self, url):
        """éªŒè¯æ— å¹¿å‘ŠURLçš„æœ‰æ•ˆæ€§"""
        try:
            response = self.session.head(url, timeout=10)
            return {
                'valid': response.status_code == 200,
                'status_code': response.status_code,
                'content_length': response.headers.get('content-length'),
                'content_type': response.headers.get('content-type')
            }
        except Exception as e:
            return {
                'valid': False,
                'error': str(e)
            }
    
    def extract_direct_m3u8_url(self, page_url):
        """
        ç›´æ¥æå–m3u8é“¾æ¥ï¼Œè·³è¿‡å¹¿å‘Šé¡µé¢
        
        åŸºäºä½ æä¾›çš„æ ¼å¼åˆ†æï¼š
        https://tup.iyinghua.com/?vid=https://8.bf8bf.com/video/SilentWitchchenmomonvdemimi/ç¬¬01é›†/index.m3u8
        """
        
        try:
            # ç›´æ¥æ„é€ m3u8é“¾æ¥
            # ä»é¡µé¢URLæå–åŠ¨æ¼«ä¿¡æ¯
            match = re.search(r'/v/(\d+)-(\d+)\.html', page_url)
            if match:
                anime_id, episode = match.groups()
                
                # åŸºäºå¸¸è§æ ¼å¼æ„é€ m3u8é“¾æ¥
                base_urls = [
                    f"https://8.bf8bf.com/video/{anime_id}/ç¬¬{int(episode):02d}é›†/index.m3u8",
                    f"https://8.bf8bf.com/video/{anime_id}/ç¬¬{episode}é›†/index.m3u8",
                    f"https://8.bf8bf.com/video/{anime_id}/ç¬¬{episode}è¯/index.m3u8",
                    f"https://8.bf8bf.com/video/{anime_id}/EP{episode.zfill(2)}/index.m3u8"
                ]
                
                # éªŒè¯é“¾æ¥
                for url in base_urls:
                    validation = self.validate_clean_url(url)
                    if validation['valid']:
                        return {
                            'success': True,
                            'm3u8_url': url,
                            'method': 'direct_construction',
                            'anime_id': anime_id,
                            'episode': episode,
                            'ad_free': True
                        }
            
            return {
                'success': False,
                'error': 'æ— æ³•æ„é€ m3u8é“¾æ¥'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }


def main():
    """æµ‹è¯•æ— å¹¿å‘Šæå–å™¨"""
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python ad_free_extractor.py <æ¨±èŠ±åŠ¨æ¼«é¡µé¢URL>")
        print("  python ad_free_extractor.py http://www.iyinghua.com/v/6543-1.html")
        return
    
    page_url = sys.argv[1]
    
    extractor = AdFreeVideoExtractor(headless=False)
    
    print("æ­£åœ¨æå–æ— å¹¿å‘Šè§†é¢‘é“¾æ¥...")
    
    # æ–¹æ³•1: é¡µé¢æ¸…ç†æ³•
    result = extractor.extract_clean_video_url(page_url)
    
    if result['success'] and result['clean_sources']:
        print("\n" + "="*60)
        print("âœ… æ— å¹¿å‘Šè§†é¢‘é“¾æ¥æå–æˆåŠŸ")
        print("="*60)
        
        for i, source in enumerate(result['clean_sources'], 1):
            print(f"{i}. ç±»å‹: {source['type']}")
            print(f"   è´¨é‡: {source['quality']}")
            print(f"   æ¥æº: {source['source']}")
            print(f"   æ— å¹¿å‘Š: {'æ˜¯' if source['ad_free'] else 'å¦'}")
            print(f"   URL: {source['url']}")
            
            # éªŒè¯é“¾æ¥
            validation = extractor.validate_clean_url(source['url'])
            if validation['valid']:
                print(f"   âœ… é“¾æ¥æœ‰æ•ˆ")
                if validation['content_length']:
                    size_mb = int(validation['content_length']) / (1024 * 1024)
                    print(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {size_mb:.2f} MB")
            else:
                print(f"   âŒ é“¾æ¥æ— æ•ˆ")
            
            print("-" * 60)
    
    # æ–¹æ³•2: ç›´æ¥æ„é€ æ³•
    print("\nå°è¯•ç›´æ¥æ„é€ m3u8é“¾æ¥...")
    direct_result = extractor.extract_direct_m3u8_url(page_url)
    
    if direct_result['success']:
        print(f"\nâœ… ç›´æ¥m3u8é“¾æ¥:")
        print(f"   URL: {direct_result['m3u8_url']}")
        print(f"   æ–¹æ³•: {direct_result['method']}")
        print(f"   æ— å¹¿å‘Š: {'æ˜¯' if direct_result['ad_free'] else 'å¦'}")
        
        validation = extractor.validate_clean_url(direct_result['m3u8_url'])
        if validation['valid']:
            print(f"   âœ… é“¾æ¥éªŒè¯é€šè¿‡")
        else:
            print(f"   âŒ é“¾æ¥éªŒè¯å¤±è´¥")
    else:
        print(f"âŒ ç›´æ¥æ„é€ å¤±è´¥: {direct_result['error']}")


if __name__ == "__main__":
    main()