#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨±èŠ±åŠ¨æ¼«æœç´¢çˆ¬è™« - å‘½ä»¤è¡Œç‰ˆæœ¬
æ”¯æŒæ‰¹é‡æœç´¢å’Œå¤šç§è¾“å‡ºæ ¼å¼
"""

import requests
from bs4 import BeautifulSoup
import json
import argparse
import sys
import urllib.parse
from datetime import datetime
import re
import os

class AnimeSearchCLI:
    def __init__(self):
        self.base_url = "http://www.iyinghua.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        }

    def search_anime(self, keyword):
        """æœç´¢åŠ¨æ¼«"""
        try:
            encoded_keyword = urllib.parse.quote(keyword)
            search_url = f"{self.base_url}/search/{encoded_keyword}/"
            
            print(f"ğŸŒ¸ æ­£åœ¨æœç´¢: {keyword}")
            print(f"ğŸ”— URL: {search_url}")
            
            response = requests.get(search_url, headers=self.headers, timeout=30)
            response.raise_for_status()
            response.encoding = 'utf-8'
            
            return self.parse_search_results(response.text, keyword)
            
        except requests.RequestException as e:
            print(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
            return []
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {str(e)}")
            return []

    def parse_search_results(self, html_content, keyword):
        """è§£ææœç´¢ç»“æœ"""
        soup = BeautifulSoup(html_content, 'html.parser')
        results = []
        
        # æŸ¥æ‰¾æœç´¢ç»“æœåˆ—è¡¨
        lpic_div = soup.find('div', class_='lpic')
        if not lpic_div:
            print("âš ï¸ æœªæ‰¾åˆ°æœç´¢ç»“æœ")
            return results
            
        anime_items = lpic_div.find_all('li')
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(anime_items)} ä¸ªåŠ¨æ¼«")
        
        for index, item in enumerate(anime_items, 1):
            try:
                anime_data = {
                    'index': index,
                    'search_keyword': keyword,
                    'search_time': datetime.now().isoformat()
                }
                
                # å›¾ç‰‡
                img_tag = item.find('img')
                if img_tag:
                    anime_data['image_url'] = img_tag.get('src', '')
                    anime_data['title_raw'] = img_tag.get('alt', '')
                
                # æ ‡é¢˜å’Œé“¾æ¥
                title_link = item.find('h2').find('a') if item.find('h2') else None
                if title_link:
                    anime_data['title'] = title_link.get_text(strip=True)
                    anime_data['detail_url'] = urllib.parse.urljoin(self.base_url, title_link.get('href', ''))
                    anime_data['detail_path'] = title_link.get('href', '')
                
                # æå–ID
                detail_path = anime_data.get('detail_path', '')
                id_match = re.search(r'/show/(\d+)\.html', detail_path)
                if id_match:
                    anime_data['anime_id'] = id_match.group(1)
                
                # ç›´æ¥è·å–çœŸå®çš„é›†æ•°æ ‡ç­¾å†…å®¹ - åŸæ ·æå–ï¼Œä¸åšä»»ä½•åˆ¤æ–­
                spans = item.find_all('span')
                episodes_text = "æœªçŸ¥"
                if spans:
                    # ç›´æ¥è·å–ç¬¬ä¸€ä¸ªspançš„å®Œæ•´æ–‡æœ¬å†…å®¹
                    episodes_text = spans[0].get_text(strip=True)
                anime_data['episodes_raw'] = episodes_text
                
                # æå–çº¯æ•°å­—é›†æ•°
                ep_match = re.search(r'(\d+)', anime_data['episodes_raw'])
                if ep_match:
                    anime_data['episodes_count'] = int(ep_match.group(1))
                else:
                    anime_data['episodes_count'] = None
                
                # ç±»å‹ä¿¡æ¯ - åŸºäºå®é™…HTMLç»“æ„ä¼˜åŒ–
                anime_data['genres'] = []
                anime_data['genres_str'] = ''
                
                spans = item.find_all('span')
                for span in spans:
                    text = span.get_text(strip=True)
                    if 'ç±»å‹ï¼š' in text:
                        type_links = span.find_all('a')
                        if type_links:
                            anime_data['genres'] = [a.get_text(strip=True) for a in type_links]
                        else:
                            # å¤„ç†æ²¡æœ‰aæ ‡ç­¾çš„æƒ…å†µï¼Œç›´æ¥ä»æ–‡æœ¬æå–
                            type_text = text.replace('ç±»å‹ï¼š', '').strip()
                            # æŒ‰å¸¸è§ç±»å‹åˆ†å‰²
                            types = []
                            common_types = ['æç¬‘', 'å†’é™©', 'æ ¡å›­', 'æ—¥å¸¸', 'å¥‡å¹»', 'ç™¾åˆ', 'æˆ˜æ–—', 'çƒ­è¡€', 'ç§‘å¹»', 'æ‹çˆ±', 'é­”æ³•', 'æ²»æ„ˆ', 'æ‚¬ç–‘', 'ææ€–', 'å†å²', 'è¿åŠ¨', 'éŸ³ä¹', 'æ ¡å›­', 'æ—¥å¸¸']
                            for t in common_types:
                                if t in type_text:
                                    types.append(t)
                            if types:
                                anime_data['genres'] = types
                            else:
                                # å¦‚æœæ— æ³•åˆ†å‰²ï¼Œå°†æ•´ä¸ªæ–‡æœ¬ä½œä¸ºä¸€ä¸ªç±»å‹
                                anime_data['genres'] = [type_text] if type_text else []
                        
                        anime_data['genres_str'] = ' '.join(anime_data['genres'])
                        break
                
                # æè¿°
                desc_p = item.find('p')
                if desc_p:
                    anime_data['description'] = desc_p.get_text(strip=True)
                
                # å®Œæ•´ä¿¡æ¯
                anime_data['source_url'] = f"{self.base_url}/search/{urllib.parse.quote(keyword)}/"
                anime_data['base_url'] = self.base_url
                
                results.append(anime_data)
                
                # å‘½ä»¤è¡Œè¾“å‡º
                print(f"\nğŸ­ [{index}] {anime_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}")
                print(f"   ğŸ“º é›†æ•°: {anime_data.get('episodes_raw', 'æœªçŸ¥')}")
                print(f"   ğŸ·ï¸  ç±»å‹: {anime_data.get('genres_str', 'æœªçŸ¥')}")
                print(f"   ğŸ”— è¯¦æƒ…: {anime_data.get('detail_url', '')}")
                if len(anime_data.get('description', '')) > 150:
                    print(f"   ğŸ“ ç®€ä»‹: {anime_data['description'][:150]}...")
                else:
                    print(f"   ğŸ“ ç®€ä»‹: {anime_data.get('description', 'æš‚æ— ç®€ä»‹')}")
                if anime_data.get('image_url'):
                    print(f"   ğŸ–¼ï¸ å›¾ç‰‡: {anime_data['image_url']}")
                
            except Exception as e:
                print(f"âš ï¸ è§£æç¬¬ {index} ä¸ªåŠ¨æ¼«å¤±è´¥: {str(e)}")
                continue
        
        return results

    def export_results(self, results, filename, format_type='json'):
        """å¯¼å‡ºç»“æœ"""
        try:
            if format_type == 'json':
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                    
            elif format_type == 'txt':
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(f"ğŸŒ¸ æ¨±èŠ±åŠ¨æ¼«æœç´¢ç»“æœ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write("=" * 80 + "\n\n")
                    
                    for anime in results:
                        f.write(f"ğŸ­ {anime.get('title', 'æœªçŸ¥æ ‡é¢˜')}\n")
                        f.write(f"ğŸ“º é›†æ•°: {anime.get('episodes', 'æœªçŸ¥')}\n")
                        f.write(f"ğŸ·ï¸  ç±»å‹: {anime.get('genres_str', 'æœªçŸ¥')}\n")
                        f.write(f"ğŸ”— è¯¦æƒ…é¡µ: {anime.get('detail_url', '')}\n")
                        f.write(f"ğŸ–¼ï¸  å›¾ç‰‡: {anime.get('image_url', '')}\n")
                        f.write(f"ğŸ“ ç®€ä»‹: {anime.get('description', 'æš‚æ— ç®€ä»‹')}\n")
                        f.write("-" * 80 + "\n\n")
                        
            elif format_type == 'csv':
                import csv
                with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.writer(f)
                    writer.writerow(['æ ‡é¢˜', 'é›†æ•°', 'ç±»å‹', 'è¯¦æƒ…é“¾æ¥', 'å›¾ç‰‡é“¾æ¥', 'åŠ¨æ¼«ID', 'ç®€ä»‹'])
                    
                    for anime in results:
                        writer.writerow([
                            anime.get('title', ''),
                            anime.get('episodes', ''),
                            anime.get('genres_str', ''),
                            anime.get('detail_url', ''),
                            anime.get('image_url', ''),
                            anime.get('anime_id', ''),
                            anime.get('description', '')
                        ])
            
            print(f"âœ… ç»“æœå·²å¯¼å‡ºåˆ°: {filename}")
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")

    def batch_search(self, keywords, output_dir=".", format_type='json'):
        """æ‰¹é‡æœç´¢"""
        all_results = {}
        
        for keyword in keywords:
            print(f"\n{'='*80}")
            print(f"æ­£åœ¨æœç´¢: {keyword}")
            print(f"{'='*80}")
            
            results = self.search_anime(keyword)
            all_results[keyword] = results
            
            # ä¸ºæ¯ä¸ªå…³é”®è¯å•ç‹¬ä¿å­˜
            if results:
                filename = f"search_{keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{format_type}"
                filename = "".join(c for c in filename if c.isalnum() or c in (' ', '-', '_', '.')).rstrip()
                filepath = os.path.join(output_dir, filename)
                self.export_results(results, filepath, format_type)
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_filename = f"batch_search_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        summary_path = os.path.join(output_dir, summary_filename)
        
        try:
            with open(summary_path, 'w', encoding='utf-8') as f:
                json.dump(all_results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“Š æ±‡æ€»ç»“æœå·²ä¿å­˜åˆ°: {summary_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ±‡æ€»ç»“æœå¤±è´¥: {str(e)}")

    def interactive_mode(self):
        """äº¤äº’æ¨¡å¼"""
        print("ğŸŒ¸ æ¨±èŠ±åŠ¨æ¼«æœç´¢å·¥å…· - äº¤äº’æ¨¡å¼")
        print("è¾“å…¥å…³é”®è¯è¿›è¡Œæœç´¢ï¼Œè¾“å…¥ 'exit' é€€å‡º")
        print("-" * 50)
        
        while True:
            keyword = input("\nè¯·è¾“å…¥æœç´¢å…³é”®è¯: ").strip()
            if keyword.lower() == 'exit':
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼")
                break
            
            if not keyword:
                print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆçš„å…³é”®è¯")
                continue
            
            results = self.search_anime(keyword)
            
            if results:
                save = input("æ˜¯å¦ä¿å­˜ç»“æœï¼Ÿ(y/n): ").strip().lower()
                if save == 'y':
                    filename = f"search_{keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    self.export_results(results, filename, 'json')


def main():
    parser = argparse.ArgumentParser(description='æ¨±èŠ±åŠ¨æ¼«æœç´¢çˆ¬è™«')
    parser.add_argument('keyword', nargs='?', help='æœç´¢å…³é”®è¯')
    parser.add_argument('-f', '--file', help='ä»æ–‡ä»¶è¯»å–å…³é”®è¯åˆ—è¡¨')
    parser.add_argument('-o', '--output', default='.', help='è¾“å‡ºç›®å½•')
    parser.add_argument('-t', '--format', choices=['json', 'txt', 'csv'], default='json', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('-i', '--interactive', action='store_true', help='äº¤äº’æ¨¡å¼')
    
    args = parser.parse_args()
    
    crawler = AnimeSearchCLI()
    
    if args.interactive:
        crawler.interactive_mode()
    elif args.file:
        # ä»æ–‡ä»¶è¯»å–å…³é”®è¯
        try:
            with open(args.file, 'r', encoding='utf-8') as f:
                keywords = [line.strip() for line in f if line.strip()]
            crawler.batch_search(keywords, args.output, args.format)
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {args.file}")
            sys.exit(1)
    elif args.keyword:
        # å•ä¸ªå…³é”®è¯æœç´¢
        results = crawler.search_anime(args.keyword)
        if results:
            filename = f"search_{args.keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{args.format}"
            crawler.export_results(results, filename, args.format)
    else:
        # äº¤äº’æ¨¡å¼
        crawler.interactive_mode()

if __name__ == "__main__":
    main()