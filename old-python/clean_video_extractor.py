#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨±èŠ±åŠ¨æ¼«çº¯å‡€è§†é¢‘æå–å™¨ v2.0
è‡ªåŠ¨å»å¹¿å‘Š + çº¯å‡€m3u8æå– + æ‰¹é‡éªŒè¯
é’ˆå¯¹ä½ æä¾›çš„å…·ä½“å¹¿å‘Šæ ¼å¼ä¼˜åŒ–
"""

import requests
import re
import json
import time
import os
from urllib.parse import urljoin, urlparse
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

class CleanVideoExtractor:
    """æ¨±èŠ±åŠ¨æ¼«çº¯å‡€è§†é¢‘æå–å™¨"""
    
    def __init__(self, headless=True):
        self.headless = headless
        self.driver = None
        self.session = requests.Session()
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Referer': 'http://www.iyinghua.com/',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        })
        
        # ä½ æä¾›çš„å…·ä½“å¹¿å‘Šç‰¹å¾
        self.ad_patterns = {
            'containers': [
                '#adv_wrap_hh',
                '.ad-banner',
                '[id*="adv"]',
                '[class*="ad"]'
            ],
            'domains': [
                'evewan.com',
                'sogowan.com',
                'v4.sogowan.com'
            ],
            'selectors': [
                'a[href*="evewan.com"]',
                'img[src*="sogowan.com"]',
                'iframe[src*="visitor"]'
            ]
        }
    
    def init_driver(self):
        """åˆå§‹åŒ–æµè§ˆå™¨é©±åŠ¨"""
        try:
            from webdriver_manager.chrome import ChromeDriverManager
            from selenium.webdriver.chrome.service import Service
            
            chrome_options = Options()
            if self.headless:
                chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            return True
        except Exception as e:
            print(f"åˆå§‹åŒ–é©±åŠ¨å¤±è´¥: {e}")
            return False
    
    def remove_specific_ads(self):
        """ç§»é™¤ä½ æä¾›çš„å…·ä½“å¹¿å‘Š"""
        
        # ä¸“é—¨é’ˆå¯¹ä½ æä¾›çš„å¹¿å‘Šæ ¼å¼çš„ç§»é™¤è„šæœ¬
        ad_removal_script = """
        // ç§»é™¤ä¸»å¹¿å‘Šå®¹å™¨ adv_wrap_hh
        var advWrap = document.getElementById('adv_wrap_hh');
        if (advWrap) {
            console.log('å‘ç°ä¸»å¹¿å‘Šå®¹å™¨ï¼Œæ­£åœ¨ç§»é™¤...');
            advWrap.style.display = 'none';
            advWrap.remove();
        }
        
        // ç§»é™¤æ‰€æœ‰åŒ…å«evewan.comçš„å¹¿å‘Šé“¾æ¥
        var evewanLinks = document.querySelectorAll('a[href*="evewan.com"]');
        evewanLinks.forEach(function(link) {
            console.log('ç§»é™¤evewan.comå¹¿å‘Šé“¾æ¥:', link.href);
            link.remove();
        });
        
        // ç§»é™¤æ‰€æœ‰sogowan.comå¹¿å‘Šå›¾ç‰‡
        var sogowanImages = document.querySelectorAll('img[src*="sogowan.com"]');
        sogowanImages.forEach(function(img) {
            console.log('ç§»é™¤sogowan.comå¹¿å‘Šå›¾ç‰‡:', img.src);
            img.remove();
        });
        
        // ç§»é™¤ç‰¹å®šçš„å¹¿å‘ŠHTMLç»“æ„
        var adDivs = document.querySelectorAll('div[style*="position: absolute"]');
        adDivs.forEach(function(div) {
            if (div.style.zIndex && parseInt(div.style.zIndex) > 1000000) {
                console.log('ç§»é™¤é«˜z-indexå¹¿å‘Šå±‚');
                div.remove();
            }
        });
        
        // ç§»é™¤iframeå¹¿å‘Š
        var adIframes = document.querySelectorAll('iframe[src*="visitor"]');
        adIframes.forEach(function(iframe) {
            console.log('ç§»é™¤è®¿å®¢å¹¿å‘Šiframe');
            iframe.remove();
        });
        
        // æ¸…ç†å¹¿å‘Šç›¸å…³çš„CSS
        var styleSheets = document.styleSheets;
        for (var i = 0; i < styleSheets.length; i++) {
            try {
                var rules = styleSheets[i].cssRules || styleSheets[i].rules;
                if (rules) {
                    for (var j = rules.length - 1; j >= 0; j--) {
                        var rule = rules[j];
                        if (rule.selectorText && rule.selectorText.includes('adv')) {
                            styleSheets[i].deleteRule(j);
                        }
                    }
                }
            } catch (e) {
                // å¿½ç•¥è·¨åŸŸæ ·å¼è¡¨é”™è¯¯
            }
        }
        """
        
        try:
            self.driver.execute_script(ad_removal_script)
            return True
        except Exception as e:
            print(f"å¹¿å‘Šç§»é™¤å¤±è´¥: {e}")
            return False
    
    def extract_pure_m3u8(self, page_url):
        """æå–çº¯å‡€çš„m3u8é“¾æ¥"""
        
        if not self.init_driver():
            return None
        
        try:
            print(f"ğŸ¯ æ­£åœ¨è®¿é—®: {page_url}")
            self.driver.get(page_url)
            
            # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            WebDriverWait(self.driver, 20).until(
                lambda driver: driver.execute_script("return document.readyState") == "complete"
            )
            
            # ç­‰å¾…è§†é¢‘å…ƒç´ 
            try:
                WebDriverWait(self.driver, 15).until(
                    EC.presence_of_element_located((By.TAG_NAME, "video"))
                )
            except:
                pass
            
            # ç­‰å¾…é¢å¤–æ—¶é—´ç¡®ä¿åŠ¨æ€å†…å®¹åŠ è½½
            time.sleep(5)
            
            # æ‰§è¡Œå¹¿å‘Šç§»é™¤
            self.remove_specific_ads()
            
            # è·å–æ¸…ç†åçš„é¡µé¢æºä»£ç 
            clean_source = self.driver.page_source
            
            # æå–çº¯å‡€è§†é¢‘é“¾æ¥
            pure_links = self._extract_clean_m3u8_links(clean_source)
            
            # éªŒè¯é“¾æ¥
            validated_links = self._validate_links(pure_links)
            
            return {
                'success': True,
                'page_url': page_url,
                'pure_m3u8': validated_links,
                'ad_removed': True,
                'extraction_method': 'dynamic_cleanup'
            }
            
        except Exception as e:
            print(f"âŒ æå–å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'pure_m3u8': []
            }
        finally:
            if self.driver:
                self.driver.quit()
    
    def _extract_clean_m3u8_links(self, page_source):
        """ä»æ¸…ç†åçš„é¡µé¢æå–m3u8é“¾æ¥"""
        
        links = []
        
        try:
            # åŸºäºä½ æä¾›çš„æ ¼å¼æå–
            
            # æ–¹æ³•1: ç›´æ¥æå–tup.iyinghua.comæ ¼å¼
            tup_pattern = r'https://tup\.iyinghua\.com/\?vid=([^&"\']+)'
            tup_matches = re.findall(tup_pattern, page_source)
            
            for vid_param in tup_matches:
                # æ¸…ç†å‚æ•°
                clean_url = vid_param.replace('$mp4', '')
                if clean_url.startswith('https://') and '.m3u8' in clean_url:
                    links.append({
                        'url': clean_url,
                        'type': 'tup_direct',
                        'quality': self._get_quality_from_url(clean_url),
                        'source': 'tup.iyinghua.com'
                    })
            
            # æ–¹æ³•2: æå–8.bf8bf.comæ ¼å¼ï¼ˆåŸºäºä½ æä¾›çš„ç¤ºä¾‹ï¼‰
            bf8bf_pattern = r'https://8\.bf8bf\.com[^"\']*\.m3u8[^"\']*'
            bf8bf_matches = re.findall(bf8bf_pattern, page_source)
            
            for url in bf8bf_matches:
                clean_url = self._clean_url(url)
                links.append({
                    'url': clean_url,
                    'type': 'bf8bf_direct',
                    'quality': self._get_quality_from_url(clean_url),
                    'source': '8.bf8bf.com'
                })
            
            # æ–¹æ³•3: æå–æ‰€æœ‰m3u8é“¾æ¥å¹¶è¿‡æ»¤å¹¿å‘Š
            all_m3u8_pattern = r'https?://[^"\']+\.m3u8[^"\']*'
            all_matches = re.findall(all_m3u8_pattern, page_source)
            
            for url in all_matches:
                # è¿‡æ»¤å¹¿å‘ŠåŸŸå
                if not any(ad_domain in url for ad_domain in self.ad_patterns['domains']):
                    clean_url = self._clean_url(url)
                    if clean_url not in [l['url'] for l in links]:
                        links.append({
                            'url': clean_url,
                            'type': 'general_m3u8',
                            'quality': self._get_quality_from_url(clean_url),
                            'source': 'direct_extraction'
                        })
            
            # æ–¹æ³•4: ä»JavaScripté…ç½®æå–
            js_configs = [
                r'player_aaaa\s*=\s*({[^}]+"url"[^}]+})',
                r'config\s*=\s*({[^}]+"video"[^}]+})',
                r'videoUrl\s*=\s*["\']([^"\']+\.m3u8[^"\']*)["\']'
            ]
            
            for pattern in js_configs:
                matches = re.findall(pattern, page_source)
                for match in matches:
                    try:
                        if isinstance(match, str) and match.startswith('{'):
                            config = json.loads(match)
                            url = config.get('url', '') or config.get('video', {}).get('url', '')
                        else:
                            url = match
                        
                        if url and '.m3u8' in url and not any(ad_domain in url for ad_domain in self.ad_patterns['domains']):
                            clean_url = self._clean_url(url)
                            if clean_url not in [l['url'] for l in links]:
                                links.append({
                                    'url': clean_url,
                                    'type': 'javascript_config',
                                    'quality': 'auto',
                                    'source': 'player_config'
                                })
                    except:
                        continue
        
        except Exception as e:
            print(f"æå–m3u8é“¾æ¥å¤±è´¥: {e}")
        
        return links
    
    def _clean_url(self, url):
        """æ¸…ç†URLä¸­çš„å¹¿å‘Šå‚æ•°"""
        
        # ç§»é™¤å¹¿å‘Šå‚æ•°
        url = re.sub(r'\$[^&]*$', '', url)
        url = re.sub(r'&ad[^&]*', '', url)
        url = re.sub(r'\?ad[^&]*', '', url)
        
        # ç§»é™¤è¿½è¸ªå‚æ•°
        url = re.sub(r'&utm_[^&]*', '', url)
        url = re.sub(r'&ref[^&]*', '', url)
        
        return url
    
    def _get_quality_from_url(self, url):
        """ä»URLæå–è´¨é‡ä¿¡æ¯"""
        url_lower = url.lower()
        
        if '1080' in url_lower or '1920x1080' in url_lower:
            return '1080p'
        elif '720' in url_lower or '1280x720' in url_lower:
            return '720p'
        elif '480' in url_lower or '854x480' in url_lower:
            return '480p'
        elif '360' in url_lower or '640x360' in url_lower:
            return '360p'
        else:
            return 'auto'
    
    def _validate_links(self, links):
        """éªŒè¯é“¾æ¥æœ‰æ•ˆæ€§"""
        
        validated_links = []
        
        for link in links:
            try:
                response = requests.head(link['url'], timeout=10, headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                })
                
                if response.status_code == 200:
                    link.update({
                        'valid': True,
                        'status_code': response.status_code,
                        'file_size': response.headers.get('content-length'),
                        'content_type': response.headers.get('content-type')
                    })
                    validated_links.append(link)
                else:
                    link.update({
                        'valid': False,
                        'status_code': response.status_code
                    })
            
            except Exception as e:
                link.update({
                    'valid': False,
                    'error': str(e)
                })
        
        return validated_links
    
    def construct_direct_url(self, page_url):
        """ç›´æ¥æ„é€ çº¯å‡€m3u8é“¾æ¥"""
        
        try:
            # ä»é¡µé¢URLæå–ä¿¡æ¯
            match = re.search(r'/v/(\d+)-(\d+)\.html', page_url)
            if match:
                anime_id, episode = match.groups()
                
                # åŸºäºä½ æä¾›çš„æ ¼å¼æ„é€ 
                direct_urls = [
                    f"https://8.bf8bf.com/video/SilentWitchchenmomonvdemimi/ç¬¬{int(episode):02d}é›†/index.m3u8",
                    f"https://8.bf8bf.com/video/{anime_id}/ç¬¬{int(episode):02d}é›†/index.m3u8",
                    f"https://8.bf8bf.com/video/{anime_id}/EP{episode.zfill(2)}/index.m3u8"
                ]
                
                for url in direct_urls:
                    if self._validate_links([{'url': url}])[0]['valid']:
                        return {
                            'success': True,
                            'direct_url': url,
                            'constructed': True,
                            'anime_id': anime_id,
                            'episode': episode,
                            'method': 'pattern_construction'
                        }
        
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
        
        return {
            'success': False,
            'error': 'æ— æ³•æ„é€ æœ‰æ•ˆé“¾æ¥'
        }
    
    def download_with_ffmpeg(self, m3u8_url, output_path):
        """ä½¿ç”¨ffmpegä¸‹è½½æ— å¹¿å‘Šè§†é¢‘"""
        
        try:
            import subprocess
            
            cmd = [
                'ffmpeg',
                '-i', m3u8_url,
                '-c', 'copy',
                '-bsf:a', 'aac_adtstoasc',
                '-y',
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                return {
                    'success': True,
                    'message': 'ä¸‹è½½æˆåŠŸ',
                    'file_path': output_path
                }
            else:
                return {
                    'success': False,
                    'error': result.stderr
                }
        
        except FileNotFoundError:
            return {
                'success': False,
                'error': 'æœªæ‰¾åˆ°ffmpegï¼Œè¯·å…ˆå®‰è£…ffmpeg'
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 2:
        print("ğŸ¯ æ¨±èŠ±åŠ¨æ¼«çº¯å‡€è§†é¢‘æå–å™¨ v2.0")
        print("="*50)
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python clean_video_extractor.py <æ¨±èŠ±åŠ¨æ¼«é¡µé¢URL>")
        print("  python clean_video_extractor.py http://www.iyinghua.com/v/6543-1.html")
        print("\nğŸ“‹ åŠŸèƒ½:")
        print("  âœ… è‡ªåŠ¨å»é™¤åµŒå¥—å¹¿å‘Š")
        print("  âœ… æå–çº¯å‡€m3u8é“¾æ¥")
        print("  âœ… éªŒè¯é“¾æ¥æœ‰æ•ˆæ€§")
        print("  âœ… æ”¯æŒæ‰¹é‡æå–")
        return
    
    page_url = sys.argv[1]
    extractor = CleanVideoExtractor(headless=False)
    
    print(f"ğŸ¯ æ­£åœ¨å¤„ç†: {page_url}")
    print("ğŸ”„ å¯åŠ¨æ— å¹¿å‘Šè§†é¢‘æå–...")
    
    # æ–¹æ³•1: åŠ¨æ€æ¸…ç†æ³•
    print("\nğŸ” æ–¹æ³•1: åŠ¨æ€é¡µé¢æ¸…ç†")
    result = extractor.extract_pure_m3u8(page_url)
    
    if result['success'] and result['pure_m3u8']:
        print("\n" + "="*70)
        print("âœ… æ— å¹¿å‘Šè§†é¢‘é“¾æ¥æå–æˆåŠŸ")
        print("="*70)
        
        for i, link in enumerate(result['pure_m3u8'], 1):
            print(f"{i}. ğŸ¬ çº¯å‡€m3u8:")
            print(f"   URL: {link['url']}")
            print(f"   ç±»å‹: {link['type']}")
            print(f"   è´¨é‡: {link['quality']}")
            print(f"   æ¥æº: {link['source']}")
            
            if link.get('valid'):
                print(f"   âœ… éªŒè¯é€šè¿‡")
                if link.get('file_size'):
                    size_mb = int(link['file_size']) / (1024 * 1024)
                    print(f"   ğŸ“Š å¤§å°: {size_mb:.2f} MB")
            else:
                print(f"   âŒ éªŒè¯å¤±è´¥")
            
            print("-" * 70)
    
    # æ–¹æ³•2: ç›´æ¥æ„é€ æ³•
    print("\nğŸ” æ–¹æ³•2: ç›´æ¥æ„é€ é“¾æ¥")
    direct_result = extractor.construct_direct_url(page_url)
    
    if direct_result['success']:
        print(f"\nâœ… ç›´æ¥æ„é€ æˆåŠŸ:")
        print(f"   ğŸ¯ çº¯å‡€m3u8: {direct_result['direct_url']}")
        print(f"   ğŸ“º åŠ¨æ¼«ID: {direct_result['anime_id']}")
        print(f"   ğŸ”¢ é›†æ•°: {direct_result['episode']}")
        print(f"   æ–¹æ³•: {direct_result['method']}")
    else:
        print(f"âŒ ç›´æ¥æ„é€ å¤±è´¥: {direct_result['error']}")
    
    # ä¸‹è½½å»ºè®®
    if (result['success'] and result['pure_m3u8']) or direct_result['success']:
        print("\n" + "="*50)
        print("ğŸ“¥ ä¸‹è½½å»ºè®®:")
        print("="*50)
        
        best_link = None
        if result['success'] and result['pure_m3u8']:
            valid_links = [l for l in result['pure_m3u8'] if l.get('valid')]
            if valid_links:
                best_link = valid_links[0]['url']
        elif direct_result['success']:
            best_link = direct_result['direct_url']
        
        if best_link:
            print(f"ğŸ¬ æ¨èä¸‹è½½é“¾æ¥:")
            print(f"   {best_link}")
            print(f"\nğŸ“¥ ä½¿ç”¨ffmpegä¸‹è½½:")
            print(f"   ffmpeg -i \"{best_link}\" -c copy output.mp4")


if __name__ == "__main__":
    main()