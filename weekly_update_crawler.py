#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨±èŠ±åŠ¨æ¼«é¦–é¡µæ¯å‘¨æ›´æ–°åˆ—è¡¨çˆ¬è™«
çˆ¬å– http://www.iyinghua.com/ é¦–é¡µçš„æ¯å‘¨æ›´æ–°åˆ—è¡¨
é€‰æ‹©å™¨ï¼š.area .side .bg .tlist ul å’Œ .area .side .bg .tlist ul li
"""

import requests
from bs4 import BeautifulSoup
import json
import time
from urllib.parse import urljoin

def crawl_weekly_updates():
    """çˆ¬å–é¦–é¡µæ¯å‘¨æ›´æ–°åˆ—è¡¨"""
    base_url = "http://www.iyinghua.com"
    url = base_url
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    try:
        print("æ­£åœ¨è®¿é—®æ¨±èŠ±åŠ¨æ¼«é¦–é¡µ...")
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        
        if response.status_code != 200:
            print(f"è®¿é—®å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return []
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # æŸ¥æ‰¾æ¯å‘¨æ›´æ–°åˆ—è¡¨
        weekly_updates = []
        
        # ä½¿ç”¨æŒ‡å®šçš„é€‰æ‹©å™¨æŸ¥æ‰¾æ›´æ–°åˆ—è¡¨
        tlist_elements = soup.select('.area .side .bg .tlist ul')
        
        print(f"æ‰¾åˆ° {len(tlist_elements)} ä¸ªæ›´æ–°åˆ—è¡¨åŒºåŸŸ")
        
        for list_idx, tlist in enumerate(tlist_elements, 1):
            # è·å–è¯¥åˆ—è¡¨ä¸­çš„æ‰€æœ‰liå…ƒç´ 
            li_elements = tlist.find_all('li')
            
            print(f"åˆ—è¡¨ {list_idx}: æ‰¾åˆ° {len(li_elements)} ä¸ªæ›´æ–°æ¡ç›®")
            
            for li_idx, li in enumerate(li_elements, 1):
                try:
                    update_data = {}
                    
                    # æå–å®Œæ•´æ–‡æœ¬
                    full_text = li.get_text(strip=True)
                    
                    # æå–åŠ¨æ¼«ä¿¡æ¯
                    title_link = li.find('a')
                    if title_link:
                        update_data['title'] = title_link.get_text(strip=True)
                        update_data['url'] = urljoin(base_url, title_link.get('href', ''))
                    else:
                        update_data['title'] = full_text
                        update_data['url'] = ''
                    
                    # æå–æ›´æ–°ä¿¡æ¯ï¼ˆå¦‚æœæœ‰spanæˆ–å…¶ä»–æ ‡ç­¾ï¼‰
                    spans = li.find_all('span')
                    update_info = []
                    for span in spans:
                        text = span.get_text(strip=True)
                        if text and text != update_data['title']:
                            update_info.append(text)
                    
                    update_data['update_info'] = ' '.join(update_info)
                    update_data['full_text'] = full_text
                    update_data['raw_html'] = str(li)
                    update_data['list_index'] = list_idx
                    update_data['item_index'] = li_idx
                    
                    weekly_updates.append(update_data)
                    
                    # æ‰“å°å‰å‡ ä¸ªä½œä¸ºç¤ºä¾‹
                    if li_idx <= 3:
                        print(f"  [{li_idx}] {update_data['title']} - {update_data['update_info']}")
                        print(f"      é“¾æ¥: {update_data['url']}")
                        print(f"      å®Œæ•´æ–‡æœ¬: {full_text}")
                        print("  " + "-" * 40)
                    
                except Exception as e:
                    print(f"å¤„ç†ç¬¬{li_idx}ä¸ªæ¡ç›®æ—¶å‡ºé”™: {e}")
                    continue
        
        return weekly_updates
        
    except requests.exceptions.RequestException as e:
        print(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
        return []
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        return []

def save_to_json(data, filename="weekly_updates.json"):
    """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
        print(f"å…±ä¿å­˜äº† {len(data)} ä¸ªæ›´æ–°æ¡ç›®")
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def create_html_viewer(data, filename="æ¯å‘¨æ›´æ–°åˆ—è¡¨.html"):
    """åˆ›å»ºHTMLæŸ¥çœ‹å™¨"""
    html_content = '''
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ¨±èŠ±åŠ¨æ¼« - æ¯å‘¨æ›´æ–°åˆ—è¡¨</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Microsoft YaHei', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #ff6b6b, #ffa726);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .stats {
            display: flex;
            justify-content: center;
            gap: 30px;
            margin-top: 15px;
        }

        .stat-item {
            text-align: center;
        }

        .stat-number {
            font-size: 2em;
            font-weight: bold;
            display: block;
        }

        .update-list {
            padding: 30px;
        }

        .update-item {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 15px;
            transition: all 0.3s;
        }

        .update-item:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
            border-color: #667eea;
        }

        .update-title {
            font-size: 1.2em;
            font-weight: bold;
            color: #333;
            margin-bottom: 8px;
        }

        .update-info {
            color: #666;
            margin-bottom: 10px;
            font-size: 14px;
        }

        .update-link {
            display: inline-block;
            padding: 8px 16px;
            background: #667eea;
            color: white;
            text-decoration: none;
            border-radius: 20px;
            font-size: 14px;
            transition: all 0.3s;
        }

        .update-link:hover {
            background: #5a6fd8;
            transform: scale(1.05);
        }

        .no-data {
            text-align: center;
            padding: 50px;
            color: #666;
            font-size: 1.2em;
        }

        .loading {
            text-align: center;
            padding: 50px;
            font-size: 1.2em;
            color: #667eea;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“… æ¨±èŠ±åŠ¨æ¼«æ¯å‘¨æ›´æ–°åˆ—è¡¨</h1>
            <p>æœ€æ–°åŠ¨æ¼«æ›´æ–°ä¸€è§ˆ</p>
            <div class="stats">
                <div class="stat-item">
                    <span class="stat-number">''' + str(len(data)) + '''</span>
                    <span>æ›´æ–°æ¡ç›®</span>
                </div>
            </div>
        </div>

        <div class="update-list">
    '''

    if data:
        for item in data:
            html_content += f'''
                <div class="update-item">
                    <div class="update-title">{item['title']}</div>
                    <div class="update-info">{item['full_text']}</div>
                    <a href="{item['url']}" target="_blank" class="update-link">ç«‹å³è§‚çœ‹</a>
                </div>
            '''
    else:
        html_content += '<div class="no-data">æš‚æ— æ›´æ–°æ•°æ®</div>'

    html_content += '''
        </div>
    </div>
</body>
</html>
    '''

    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"HTMLæŸ¥çœ‹å™¨å·²åˆ›å»º: {filename}")
    except Exception as e:
        print(f"åˆ›å»ºHTMLæŸ¥çœ‹å™¨æ—¶å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("æ¨±èŠ±åŠ¨æ¼«æ¯å‘¨æ›´æ–°åˆ—è¡¨çˆ¬è™«")
    print("=" * 80)
    
    weekly_data = crawl_weekly_updates()
    
    if weekly_data:
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        json_filename = f"weekly_updates_{timestamp}.json"
        save_to_json(weekly_data, json_filename)
        
        # åˆ›å»ºHTMLæŸ¥çœ‹å™¨
        html_filename = f"æ¯å‘¨æ›´æ–°åˆ—è¡¨_{timestamp}.html"
        create_html_viewer(weekly_data, html_filename)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print("\n" + "=" * 60)
        print("çˆ¬å–å®Œæˆï¼")
        print(f"æ€»è®¡: {len(weekly_data)} ä¸ªæ›´æ–°æ¡ç›®")
        
        # æ˜¾ç¤ºå‰10ä¸ªä½œä¸ºé¢„è§ˆ
        print("\nå‰10ä¸ªæ›´æ–°é¢„è§ˆ:")
        for i, update in enumerate(weekly_data[:10], 1):
            print(f"{i:2d}. {update['title']} - {update['full_text']}")
        
    else:
        print("æœªèƒ½è·å–åˆ°æ›´æ–°æ•°æ®")

if __name__ == "__main__":
    main()